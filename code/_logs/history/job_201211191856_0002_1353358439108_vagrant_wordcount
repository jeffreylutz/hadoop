Meta VERSION="1" .
Job JOBID="job_201211191856_0002" JOBNAME="wordcount" USER="vagrant" SUBMIT_TIME="1353358439108" JOBCONF="hdfs://node1\.big\.com:8020/user/vagrant/\.staging/job_201211191856_0002/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201211191856_0002" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201211191856_0002" LAUNCH_TIME="1353358439681" TOTAL_MAPS="2" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201211191856_0002_m_000003" TASK_TYPE="SETUP" START_TIME="1353358439682" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201211191856_0002_m_000003" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000003_0" START_TIME="1353358440458" TRACKER_NAME="tracker_node2\.big\.com:localhost/127\.0\.0\.1:38976" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201211191856_0002_m_000003" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1353358443076" HOSTNAME="/default/node2\.big\.com" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143638)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(50)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(76730368)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(895750144)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_m_000003" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1353358443147" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143638)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(50)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(76730368)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(895750144)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201211191856_0002" JOB_STATUS="RUNNING" .
Task TASKID="task_201211191856_0002_m_000000" TASK_TYPE="MAP" START_TIME="1353358445125" SPLITS="/default/node1\.big\.com,/default/node3\.big\.com,/default/node2\.big\.com" .
Task TASKID="task_201211191856_0002_m_000001" TASK_TYPE="MAP" START_TIME="1353358445133" SPLITS="/default/node1\.big\.com,/default/node3\.big\.com,/default/node2\.big\.com" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201211191856_0002_m_000000" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000000_0" START_TIME="1353358445935" TRACKER_NAME="tracker_node3\.big\.com:localhost/127\.0\.0\.1:40677" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201211191856_0002_m_000000" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1353358448932" HOSTNAME="/default/node3\.big\.com" STATE_STRING="hdfs://node1\.big\.com:8020/user/cloudera/wordcount/input/file01:0+23" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143716)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(138)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(MAP_OUTPUT_BYTES)(Map output bytes)(38)][(SPLIT_RAW_BYTES)(Input split bytes)(115)][(COMBINE_INPUT_RECORDS)(Combine input records)(4)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(3)][(SPILLED_RECORDS)(Spilled Records)(3)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(270)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(129810432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(903204864)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(81661952)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(23)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1353358449123" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143716)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(138)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(MAP_OUTPUT_BYTES)(Map output bytes)(38)][(SPLIT_RAW_BYTES)(Input split bytes)(115)][(COMBINE_INPUT_RECORDS)(Combine input records)(4)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(3)][(SPILLED_RECORDS)(Spilled Records)(3)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(270)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(129810432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(903204864)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(81661952)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(23)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201211191856_0002_m_000001" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000001_0" START_TIME="1353358446066" TRACKER_NAME="tracker_node1\.big\.com:localhost/127\.0\.0\.1:42091" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201211191856_0002_m_000001" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1353358449320" HOSTNAME="/default/node1\.big\.com" STATE_STRING="hdfs://node1\.big\.com:8020/user/cloudera/wordcount/input/file02:0+23" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143716)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(138)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(MAP_OUTPUT_BYTES)(Map output bytes)(38)][(SPLIT_RAW_BYTES)(Input split bytes)(115)][(COMBINE_INPUT_RECORDS)(Combine input records)(4)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(3)][(SPILLED_RECORDS)(Spilled Records)(3)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(250)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(131477504)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(903204864)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(81661952)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(23)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1353358449397" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143716)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(138)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(MAP_OUTPUT_BYTES)(Map output bytes)(38)][(SPLIT_RAW_BYTES)(Input split bytes)(115)][(COMBINE_INPUT_RECORDS)(Combine input records)(4)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(3)][(SPILLED_RECORDS)(Spilled Records)(3)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(250)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(131477504)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(903204864)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(81661952)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(23)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_r_000000" TASK_TYPE="REDUCE" START_TIME="1353358450038" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201211191856_0002_r_000000" TASK_ATTEMPT_ID="attempt_201211191856_0002_r_000000_0" START_TIME="1353358450030" TRACKER_NAME="tracker_node3\.big\.com:localhost/127\.0\.0\.1:40677" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201211191856_0002_r_000000" TASK_ATTEMPT_ID="attempt_201211191856_0002_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1353358452591" SORT_FINISHED="1353358452692" FINISH_TIME="1353358454058" HOSTNAME="/default/node3\.big\.com" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(68)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143416)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(22)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(92)][(REDUCE_INPUT_RECORDS)(Reduce input records)(6)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(3)][(SPILLED_RECORDS)(Spilled Records)(6)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(790)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(87711744)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(916901888)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1353358454283" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(68)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143416)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(22)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(92)][(REDUCE_INPUT_RECORDS)(Reduce input records)(6)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(3)][(SPILLED_RECORDS)(Spilled Records)(6)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(790)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(87711744)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(916901888)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_m_000002" TASK_TYPE="CLEANUP" START_TIME="1353358454286" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201211191856_0002_m_000002" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000002_0" START_TIME="1353358454274" TRACKER_NAME="tracker_node3\.big\.com:localhost/127\.0\.0\.1:40677" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201211191856_0002_m_000002" TASK_ATTEMPT_ID="attempt_201211191856_0002_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1353358456522" HOSTNAME="/default/node3\.big\.com" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143638)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(80)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(78000128)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(896802816)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201211191856_0002_m_000002" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1353358456714" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143638)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(80)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(78000128)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(896802816)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201211191856_0002" FINISH_TIME="1353358456716" JOB_STATUS="SUCCESS" FINISHED_MAPS="2" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(287432)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(276)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(4)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(MAP_OUTPUT_BYTES)(Map output bytes)(76)][(SPLIT_RAW_BYTES)(Input split bytes)(230)][(COMBINE_INPUT_RECORDS)(Combine input records)(8)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(6)][(SPILLED_RECORDS)(Spilled Records)(6)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(520)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(261287936)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(1806409728)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(163323904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(46)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(68)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(143416)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(22)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(92)][(REDUCE_INPUT_RECORDS)(Reduce input records)(6)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(3)][(SPILLED_RECORDS)(Spilled Records)(6)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(790)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(87711744)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(916901888)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(31784960)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(68)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(430848)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(276)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(22)][(HDFS_READ_OPS)(HDFS: Number of read operations)(5)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(2)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(2)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(11117)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(4028)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(MAP_OUTPUT_BYTES)(Map output bytes)(76)][(SPLIT_RAW_BYTES)(Input split bytes)(230)][(COMBINE_INPUT_RECORDS)(Combine input records)(8)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(6)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(3)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(92)][(REDUCE_INPUT_RECORDS)(Reduce input records)(6)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(3)][(SPILLED_RECORDS)(Spilled Records)(12)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(348999680)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(2723311616)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(195108864)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(46)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
